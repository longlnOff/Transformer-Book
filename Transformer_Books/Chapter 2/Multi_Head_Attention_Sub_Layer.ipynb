{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Represent the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 4\n",
    "num_inputs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1\n",
      "d_model: 4\n",
      "num_inputs: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 1., 0.],\n",
       "       [0., 2., 0., 2.],\n",
       "       [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Step: 1\\nd_model: {}\\nnum_inputs: {}\".format(d_model, num_inputs))\n",
    "\n",
    "x =np.array([[1.0, 0.0, 1.0, 0.0],  # Input 1\n",
    "            [0.0, 2.0, 0.0, 2.0],   # Input 2\n",
    "            [1.0, 1.0, 1.0, 1.0]])  # Input 3\n",
    "x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Initializing the weight matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2, weights 3 dimnesions x d_model=4\n"
     ]
    }
   ],
   "source": [
    "print(\"Step 2, weights 3 dimnesions x d_model=4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_query\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 1]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"w_query\")\n",
    "w_query =np.array([[1, 0, 1],\n",
    "                [1, 0, 0],\n",
    "                [0, 0, 1],\n",
    "                [0, 1, 1]])\n",
    "\n",
    "w_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_key\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [1, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 1, 0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"w_key\")\n",
    "w_key =np.array([[0, 0, 1],\n",
    "                [1, 1, 0],\n",
    "                [0, 1, 0],\n",
    "                [1, 1, 0]])\n",
    "w_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_value\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 2, 0],\n",
       "       [0, 3, 0],\n",
       "       [1, 0, 3],\n",
       "       [1, 1, 0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"w_value\")\n",
    "w_value = np.array([[0, 2, 0],\n",
    "                    [0, 3, 0],\n",
    "                    [1, 0, 3],\n",
    "                    [1, 1, 0]])\n",
    "w_value"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Matrix multiplication to obtain Q, K, and V\n",
    "\n",
    ">> We will now multiply the input vectors by the weight matrices to obtain a query, key, and value\n",
    "vector for each input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: Matrix multiplication to obtain Q,K,V\n",
      "Query: x * w_query\n",
      "[[1. 0. 2.]\n",
      " [2. 2. 2.]\n",
      " [2. 1. 3.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Step 3: Matrix multiplication to obtain Q,K,V\")\n",
    "print(\"Query: x * w_query\")\n",
    "Q=np.matmul(x,w_query)\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: x * w_key\n",
      "[[0. 1. 1.]\n",
      " [4. 4. 0.]\n",
      " [2. 3. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Key: x * w_key\")\n",
    "K=np.matmul(x,w_key)\n",
    "print(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value: x * w_value\n",
      "[[1. 2. 3.]\n",
      " [2. 8. 0.]\n",
      " [2. 6. 3.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Value: x * w_value\")\n",
    "V=np.matmul(x,w_value)\n",
    "print(V)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Scaled attention scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4: Scaled Attention Scores\n",
      "[[1.15470054 2.30940108 2.30940108]\n",
      " [2.30940108 9.23760431 6.92820323]\n",
      " [2.30940108 6.92820323 5.77350269]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Step 4: Scaled Attention Scores\")\n",
    "k_d=3\n",
    "#square root of k_d=3 rounded down to 1 for this example\n",
    "attention_scores = (Q @ K.transpose())/np.sqrt(k_d)\n",
    "print(attention_scores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Scaled softmax attention scores for each vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5: Scaled softmax attention_scores for each vector\n",
      "[0.1361258 0.4319371 0.4319371]\n",
      "[8.90447391e-04 9.08842647e-01 9.02669054e-02]\n",
      "[0.00744489 0.75470758 0.23784753]\n"
     ]
    }
   ],
   "source": [
    "print(\"Step 5: Scaled softmax attention_scores for each vector\")\n",
    "attention_scores[0]=softmax(attention_scores[0])\n",
    "attention_scores[1]=softmax(attention_scores[1])\n",
    "attention_scores[2]=softmax(attention_scores[2])\n",
    "print(attention_scores[0])\n",
    "print(attention_scores[1])\n",
    "print(attention_scores[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: The final attention representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6: attention value obtained by score1/k_d * V\n",
      "[1. 2. 3.]\n",
      "[2. 8. 0.]\n",
      "[2. 6. 3.]\n",
      "Attention 1\n",
      "[0.1361258  0.2722516  0.40837739]\n",
      "Attention 2\n",
      "[0.8638742  3.45549681 0.        ]\n",
      "Attention 3\n",
      "[0.8638742  2.59162261 1.2958113 ]\n"
     ]
    }
   ],
   "source": [
    "print(\"Step 6: attention value obtained by score1/k_d * V\")\n",
    "print(V[0])\n",
    "print(V[1])\n",
    "print(V[2])\n",
    "print(\"Attention 1\")\n",
    "attention1=attention_scores[0].reshape(-1,1)\n",
    "attention1=attention_scores[0][0]*V[0]\n",
    "print(attention1)\n",
    "print(\"Attention 2\")\n",
    "attention2=attention_scores[0][1]*V[1]\n",
    "print(attention2)\n",
    "print(\"Attention 3\")\n",
    "attention3=attention_scores[0][2]*V[2]\n",
    "print(attention3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Summing up the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7: summed the results to create the first line of the output matrix\n",
      "[1.8638742  6.31937101 1.7041887 ]\n"
     ]
    }
   ],
   "source": [
    "print(\"Step 7: summed the results to create the first line of the output matrix\")\n",
    "attention_input1=attention1+attention2+attention3\n",
    "print(attention_input1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Steps 1 to 7 for all the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8: Step 1 to 7 for inputs 1 to 3\n",
      "[[8.24859659e-01 7.60556023e-01 8.83689840e-01 1.15265212e-04\n",
      "  7.10441296e-01 5.89614305e-01 1.53699583e-01 7.11568853e-02\n",
      "  4.40883363e-01 3.59541317e-01 2.68940293e-01 5.56302084e-01\n",
      "  1.37928957e-03 8.95447209e-01 3.22348158e-01 9.91331155e-01\n",
      "  6.66787366e-01 9.52685046e-01 5.44194990e-02 9.34306880e-01\n",
      "  3.66149979e-02 3.99657194e-01 9.76992955e-01 5.17889447e-01\n",
      "  7.63209663e-01 3.24616026e-01 2.18124783e-01 5.03773780e-01\n",
      "  7.45387077e-02 7.52548805e-01 5.43039412e-01 3.12124503e-01\n",
      "  8.69622622e-01 3.07280766e-01 7.57450557e-01 7.94524705e-01\n",
      "  3.21616920e-01 7.95210866e-02 9.97776744e-01 2.51340285e-01\n",
      "  5.52160281e-01 6.30664248e-01 1.08351210e-01 9.10212989e-01\n",
      "  8.88401912e-03 2.59325293e-01 7.25931095e-01 4.60036619e-01\n",
      "  6.60118657e-01 9.37065022e-01 1.14424572e-01 8.67366361e-01\n",
      "  2.38109930e-01 9.26472090e-01 4.95820807e-01 3.54165605e-01\n",
      "  7.84194779e-02 4.33090374e-01 9.71595440e-01 7.08742329e-01\n",
      "  5.87650881e-01 5.94664849e-01 7.42586070e-01 5.38279918e-01]\n",
      " [4.95436608e-01 2.72368132e-01 8.43301120e-01 8.09955005e-01\n",
      "  4.63144819e-01 4.82936131e-01 4.89474203e-01 1.66107269e-01\n",
      "  4.79189268e-01 9.44450501e-01 6.48863253e-01 3.39342524e-01\n",
      "  1.26776581e-01 7.15116154e-01 1.91755804e-01 3.31896000e-01\n",
      "  8.96214851e-01 1.21973501e-01 6.07672598e-01 7.31288493e-02\n",
      "  4.34424352e-01 6.72797576e-02 7.70489379e-01 2.38914962e-01\n",
      "  8.42985779e-01 2.74345499e-01 3.35683068e-01 3.10320751e-01\n",
      "  3.61183660e-01 2.62326775e-01 5.82701195e-01 9.08539669e-01\n",
      "  9.46963497e-01 7.46473239e-01 5.17127823e-01 9.81533808e-02\n",
      "  3.22464904e-01 2.92780744e-01 1.83536817e-01 5.73922427e-01\n",
      "  1.46219820e-01 1.98586739e-01 4.54853663e-01 7.89372420e-01\n",
      "  8.02328157e-01 7.38267337e-01 8.64329267e-01 6.98083809e-01\n",
      "  1.15690181e-01 2.78166384e-01 1.37323851e-02 6.88981146e-01\n",
      "  8.55122438e-01 5.25269883e-01 8.61135735e-01 9.66292876e-02\n",
      "  5.18575743e-01 9.32053901e-01 8.73873147e-01 7.21691850e-01\n",
      "  7.53863953e-01 5.49150133e-01 7.83969698e-01 7.14326207e-01]\n",
      " [1.89679825e-01 3.44427604e-01 2.69623788e-01 4.06019215e-01\n",
      "  3.30956740e-01 9.86767353e-01 4.90736850e-01 6.48296837e-01\n",
      "  1.58139450e-01 6.82304712e-01 7.51846421e-02 5.46870135e-01\n",
      "  9.15336170e-02 1.59010250e-02 2.26209774e-01 7.24501368e-02\n",
      "  6.71977145e-01 5.41633362e-01 1.91875249e-02 7.27119501e-02\n",
      "  7.66784633e-01 8.14242935e-01 1.30383335e-01 8.39307490e-01\n",
      "  5.91211618e-01 4.59627067e-01 5.86526158e-03 7.90329738e-01\n",
      "  4.21231388e-01 5.20189673e-01 1.58793326e-01 2.45496785e-01\n",
      "  8.85584795e-01 3.29485790e-01 1.75936031e-01 9.59025556e-01\n",
      "  6.80437327e-01 7.65453973e-01 6.41605621e-01 7.78783937e-01\n",
      "  5.37002474e-01 2.65254923e-01 3.87917931e-01 2.62183155e-01\n",
      "  7.50050889e-01 3.50923598e-01 7.04114907e-01 5.83278589e-01\n",
      "  9.46847708e-01 7.83094917e-02 1.26949745e-01 8.42119336e-01\n",
      "  8.07942444e-01 4.59492710e-01 5.37198269e-01 9.82187008e-03\n",
      "  8.74993728e-01 1.88503188e-01 5.85673208e-02 7.23950690e-01\n",
      "  7.62227568e-01 2.24626735e-01 7.26930963e-01 3.71418453e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Step 8: Step 1 to 7 for inputs 1 to 3\")\n",
    "# We assume we have 3 results with learned weights (they were not trained\n",
    "# in this example)\n",
    "# We assume we are implementing the original Transformer paper.We will have\n",
    "# 3 results of 64 dimensions each\n",
    "attention_head1=np.random.random((3, 64))\n",
    "print(attention_head1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: The output of the heads of the attention sublayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9: We assume we have trained the 8 heads of the attention sublayer\n",
      "shape of one head (3, 64) \n",
      "dimension of 8 heads 512\n"
     ]
    }
   ],
   "source": [
    "# We assume that we have trained the 8 heads of the attention sublayer. The Transformer now has 3\n",
    "# output vectors (of the 3 input vectors that are words or word pieces) of d_model = 64 dimensions each:\n",
    "print(\"Step 9: We assume we have trained the 8 heads of the attention sublayer\")\n",
    "z0h1=np.random.random((3, 64))\n",
    "z1h2=np.random.random((3, 64))\n",
    "z2h3=np.random.random((3, 64))\n",
    "z3h4=np.random.random((3, 64))\n",
    "z4h5=np.random.random((3, 64))\n",
    "z5h6=np.random.random((3, 64))\n",
    "z6h7=np.random.random((3, 64))\n",
    "z7h8=np.random.random((3, 64))\n",
    "print(\"shape of one head\",z0h1.shape,\"\\ndimension of 8 heads\",64*8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10: Concatenation of the output of the heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10: Concantenation of heads 1 to 8 to obtain the original 8x64=512 ouput dimension of the model\n",
      "[[0.11739286 0.68214805 0.07517389 ... 0.30970564 0.48738415 0.30776542]\n",
      " [0.12471924 0.52269836 0.59861807 ... 0.14236979 0.30968904 0.62350204]\n",
      " [0.30895642 0.6722681  0.38038981 ... 0.13022529 0.30561542 0.07303612]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, (3, 512))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Step 10: Concantenation of heads 1 to 8 to obtain the original 8x64=512 ouput dimension of the model\")\n",
    "output_attention=np.hstack((z0h1,z1h2,z2h3,z3h4,z4h5,z5h6,z6h7,z7h8))\n",
    "print(output_attention), output_attention.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-06 17:05:31.710445: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-06 17:05:32.339716: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-11.2/lib64\n",
      "2023-02-06 17:05:32.339778: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-11.2/lib64\n",
      "2023-02-06 17:05:32.339783: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.pipelines because of the following error (look up to see its traceback):\n/home/adminvbdi/anaconda3/lib/python3.9/site-packages/torch/lib/libtorch_cuda_cpp.so: undefined symbol: cudaGraphRetainUserObject, version libcudart.so.11.0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/utils/import_utils.py:1110\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1109\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m importlib\u001b[39m.\u001b[39;49mimport_module(\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m module_name, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m)\n\u001b[1;32m   1111\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/importlib/__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    126\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 127\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:986\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:680\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:850\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:228\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/pipelines/__init__.py:49\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     41\u001b[0m     HUGGINGFACE_CO_RESOLVE_ENDPOINT,\n\u001b[1;32m     42\u001b[0m     is_kenlm_available,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m     logging,\n\u001b[1;32m     48\u001b[0m )\n\u001b[0;32m---> 49\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39maudio_classification\u001b[39;00m \u001b[39mimport\u001b[39;00m AudioClassificationPipeline\n\u001b[1;32m     50\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mautomatic_speech_recognition\u001b[39;00m \u001b[39mimport\u001b[39;00m AutomaticSpeechRecognitionPipeline\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/pipelines/audio_classification.py:22\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m add_end_docstrings, is_torch_available, logging\n\u001b[0;32m---> 22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m PIPELINE_INIT_ARGS, Pipeline\n\u001b[1;32m     25\u001b[0m \u001b[39mif\u001b[39;00m is_torch_available():\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/pipelines/base.py:34\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature_extraction_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m PreTrainedFeatureExtractor\n\u001b[0;32m---> 34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodelcard\u001b[39;00m \u001b[39mimport\u001b[39;00m ModelCard\n\u001b[1;32m     35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mauto\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfiguration_auto\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoConfig\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/modelcard.py:47\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mauto\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodeling_auto\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     33\u001b[0m     MODEL_FOR_AUDIO_CLASSIFICATION_MAPPING_NAMES,\n\u001b[1;32m     34\u001b[0m     MODEL_FOR_CAUSAL_LM_MAPPING_NAMES,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m     MODEL_FOR_TOKEN_CLASSIFICATION_MAPPING_NAMES,\n\u001b[1;32m     46\u001b[0m )\n\u001b[0;32m---> 47\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtraining_args\u001b[39;00m \u001b[39mimport\u001b[39;00m ParallelMode\n\u001b[1;32m     48\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     49\u001b[0m     MODEL_CARD_NAME,\n\u001b[1;32m     50\u001b[0m     cached_file,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     56\u001b[0m     logging,\n\u001b[1;32m     57\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/training_args.py:28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpackaging\u001b[39;00m \u001b[39mimport\u001b[39;00m version\n\u001b[0;32m---> 28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdebug_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m DebugOption\n\u001b[1;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtrainer_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     30\u001b[0m     EvaluationStrategy,\n\u001b[1;32m     31\u001b[0m     FSDPOption,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m     ShardedDDPOption,\n\u001b[1;32m     36\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/debug_utils.py:21\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39mif\u001b[39;00m is_torch_available():\n\u001b[0;32m---> 21\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m     24\u001b[0m logger \u001b[39m=\u001b[39m logging\u001b[39m.\u001b[39mget_logger(\u001b[39m__name__\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/__init__.py:218\u001b[0m\n\u001b[1;32m    217\u001b[0m         _load_global_deps()\n\u001b[0;32m--> 218\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_C\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m  \u001b[39m# noqa: F403\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[39m# Appease the type checker; ordinarily this binding is inserted by the\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[39m# torch._C module initialization code in C\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: /home/adminvbdi/anaconda3/lib/python3.9/site-packages/torch/lib/libtorch_cuda_cpp.so: undefined symbol: cudaGraphRetainUserObject, version libcudart.so.11.0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m pipeline\n\u001b[1;32m      2\u001b[0m translator \u001b[39m=\u001b[39m pipeline(\u001b[39m\"\u001b[39m\u001b[39mtranslation_en_to_fr\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m translator(\u001b[39m\"\u001b[39m\u001b[39mHello, my dog is cute\u001b[39m\u001b[39m\"\u001b[39m, max_length\u001b[39m=\u001b[39m\u001b[39m40\u001b[39m)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1055\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/utils/import_utils.py:1100\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_module(name)\n\u001b[1;32m   1099\u001b[0m \u001b[39melif\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_class_to_module\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m-> 1100\u001b[0m     module \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_module(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_class_to_module[name])\n\u001b[1;32m   1101\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(module, name)\n\u001b[1;32m   1102\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/utils/import_utils.py:1112\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1110\u001b[0m     \u001b[39mreturn\u001b[39;00m importlib\u001b[39m.\u001b[39mimport_module(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m module_name, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m   1111\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> 1112\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1113\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to import \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mmodule_name\u001b[39m}\u001b[39;00m\u001b[39m because of the following error (look up to see its\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1114\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m traceback):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1115\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.pipelines because of the following error (look up to see its traceback):\n/home/adminvbdi/anaconda3/lib/python3.9/site-packages/torch/lib/libtorch_cuda_cpp.so: undefined symbol: cudaGraphRetainUserObject, version libcudart.so.11.0"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "translator = pipeline(\"translation_en_to_fr\")\n",
    "translator(\"Hello, my dog is cute\", max_length=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:26:10) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c695a7c1db73d51cd02270fbcc6a5336958d25b354c79109e8794cb4835c69ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
